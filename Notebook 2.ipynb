{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook n°2 - NBA Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Récupération des données\n",
    "\n",
    "On procède ici à un scrapping des données depuis le site officiel de la NBA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import time\n",
    "pd.set_option('display.max_columns', None) # pour afficher toutes les colonnes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On commence par un test avec l'url nécessaire pour récupérer ces données, ce qui nous permet de définir les en-têtes (`headers`) que l'on souhaite récupérer. Comme l'url ne eprmet de récupérer les données que d'une saison et d'un type de saison à la fois, on ajoute ces deux colonnes au `DataFrame` final afin de réaliser un fichier global contenant toutes les saisons et types de saisons souhaités.\n",
    "Dans notre cas, on va récupérer les données de 2013 à 2024."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_url ='https://stats.nba.com/stats/leagueLeaders?LeagueID=00&PerMode=Totals&Scope=S&Season=2022-23&SeasonType=Regular%20Season&StatCategory=PTS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(test_url).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_headers = r['resultSet']['headers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cols = ['Year', 'Season_type'] + table_headers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers ={\n",
    "    'Accept': '*/*',\n",
    "    'Accept-Encoding': 'gzip, deflate, br, zstd',\n",
    "    'Accept-Language': 'fr-FR,fr;q=0.9,en-US;q=0.8,en;q=0.7,de;q=0.6,ar;q=0.5,af;q=0.4',\n",
    "    'Connection': 'keep-alive',\n",
    "    'Host': 'stats.nba.com',\n",
    "    'Origin': 'https://www.nba.com',\n",
    "    'Referer': 'https://www.nba.com/',\n",
    "    'Sec-Fetch-Dest': 'empty',\n",
    "    'Sec-Fetch-Mode': 'cors',\n",
    "    'Sec-Fetch-Site': 'same-site',\n",
    "    'User-Agent': 'Mozilla/5.0 (Linux; Android 6.0; Nexus 5 Build/MRA58N) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Mobile Safari/537.36',\n",
    "    'sec-ch-ua': '\"Chromium\";v=\"124\", \"Google Chrome\";v=\"124\", \"Not-A.Brand\";v=\"99\"',\n",
    "    'sec-ch-ua-mobile': '?1',\n",
    "    'sec-ch-ua-platform': '\"Android\"'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La méthode suivante permet de procéder au scrapping des données. Pour ce faire, on a défini plus haut un \"headers\", qui regroupe les informations supplémentaires envoyées avec la requête HTTP et fournissent des détails sur le client et ses préférences au serveur Web.\n",
    "Ensuite, on défini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rudyv\\AppData\\Local\\Temp\\ipykernel_10200\\822764647.py:14: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, temp_df3], axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping terminé pour la saison 2013-14 et le type de saison Regular%20Season.\n",
      "Pause de 32.5 secondes avant de continuer...\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=df_cols)\n",
    "season_types = ['Regular%20Season', 'Playoffs']\n",
    "years = ['2013-14', '2014-15', '2015-16', '2016-17', '2017-18', '2018-19', '2019-20', '2020-21', '2021-22', '2022-23', '2023-24']\n",
    "begin = time.time()\n",
    "\n",
    "for y in years :\n",
    "    for s in season_types :\n",
    "        api_url = 'https://stats.nba.com/stats/leagueLeaders?LeagueID=00&PerMode=Totals&Scope=S&Season='+y+'&SeasonType='+s+'&StatCategory=PTS'\n",
    "        r= requests.get(url=api_url, headers=headers).json()\n",
    "        temp_df1 = pd.DataFrame(r['resultSet']['rowSet'], columns=table_headers)\n",
    "        temp_df2 = pd.DataFrame({'Year':[y for i in range(len(temp_df1))],\n",
    "                                'Season_type':[s for i in range(len(temp_df1))]})\n",
    "        temp_df3 = pd.concat([temp_df2, temp_df1], axis=1)\n",
    "        df = pd.concat([df, temp_df3], axis=0)\n",
    "        print(f'Scraping terminé pour la saison {y} et le type de saison {s}.')\n",
    "        lag = np.random.uniform(low=5, high=40)\n",
    "        print(f'Pause de {round(lag,1)} secondes avant de continuer...')\n",
    "        time.sleep(lag)\n",
    "\n",
    "print(f'Scraping terminé ! Durée totale : {round((time.time()-begin)/60, 2)}')\n",
    "df.to_csv('nba_player_data_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nba",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
